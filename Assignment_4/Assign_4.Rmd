---
title:"K - Means Clustering"
output:html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
dir.create("images")

# clean the workspace
rm(list = ls())
```
***
a.

Use only the numerical variables (1 to 9) to cluster the 21 firms. Justify the various choices made in
conducting the cluster analysis, such as weights for different variables, the specific clustering algorithm(s)
used, the number of clusters formed, and so on.

Install the required packages, as required, and libraries. Load the Pharmaceuticals.csv data file into Mydata Variable. 

Select the required 9 numerical variables(columns 3 to 11) and store the data in variable Mydata1.

Dispaly the first 6 rows of data and summary statistics for the data in Mydata1 using head and summary functions respectively.

```{r}
# install.packages("tidyverse") # if necessary
library(tidyverse)  # data manipulation
# install.packages("factoextra") # if necessary
library(factoextra) # clustering algorithms & visualization
#install.packages("flexclust")
library(flexclust)
#install.packages("ggcorrplot")
library(ggcorrplot)
#install.packages("FactoMineR")
library(FactoMineR)
#install.packages("cluster")
library(cluster)



Mydata <- read.csv("Pharmaceuticals.csv")
Mydata1 <- Mydata[3:11]

head(Mydata1)
summary(Mydata1)
```
***
We will scale the data in Mydata1 as the variables are measured in diffrent weights across the rows and store the scaled data in Mydata2 dataframe.

Calculate the distance between the rows of data and vizulaize the distance matrix using get_dist and fviz_dist functions which are available in factoextra package.

```{r}
# Scaling the data frame (z-score) 

Mydata2 <- scale(Mydata1)
row.names(Mydata2) <- Mydata[,1]
distance <- get_dist(Mydata2)
fviz_dist(distance)
```

Creating and printing correlation Matrix to check the correlation among major variables

```{r}
corr <- cor(Mydata2)
ggcorrplot(corr, outline.color = "grey50", lab = TRUE, hc.order = TRUE, type = "full") 
```

***
Correlation Matrix shows that there is a strong correlation among ROA,ROE,Net_Profit_Margin and Market_Cap

We will rely on Principal Component Analysis to find out the weightage of major variables in the data set.

```{r}
pca <- PCA(Mydata2)

var <- get_pca_var(pca)

fviz_pca_var(pca, col.var="contrib",
             gradient.cols = c("green", "red", "blue"),
             repel = TRUE 
             ) + 
  labs( title = "PCA Variable Variance")
```

***
From PCA Variable Variance , we can say that ROA,ROE, Net_Profit_Margin,Market_Cap and Asset_Turnover contribute over 61% to the 2 components/dimensions of PCA (Variables)

Lets find out the optimal number of customers by using elbow method , iterating the number of clusters from 1 to 10.

```{r}
set.seed(10)

wss <- vector()
for(i in 1:10) wss[i] <- sum(kmeans(Mydata2,i)$withinss)
  
  
plot(1:10, wss , type = "b" , main = paste('Cluster of Companies') , xlab = "Number of Clusters", ylab="wss")

wss
```
***
From the above graph and wss data, we can see that the optimal cluster is at 5 as the distance between clusters is decreasing at a slower pace from cluster number 5 and onwards. 

## Silhouette Method

Now lets find out the best number of clusters using Silhouette Method 

```{r}
fviz_nbclust(Mydata2, kmeans, method = "silhouette")
```

***
Even silhouette method shows that 5 is the ideal number of clusters. In the graph we look at the large values for the Silhouette Width.

Let us now run the k-means algorithm to cluster the companies with the best number of clusters, i.e, 5.

```{r}
set.seed(1)
k5 <- kmeans(Mydata2, centers = 5, nstart = 25) # k = 5, number of restarts = 25
# Visualize the output
k5$centers # output the centers
k5$size # Number of companies in each cluster
fviz_cluster(k5, data = Mydata2) # Visualize the output
```

***
Five clusters are displayed each with 4, 2, 3, 4, and  8 data points (companies) respectively

kmeans clustering, using Manhattan Distance

```{r}
set.seed(1)

k51 = kcca(Mydata2, k=5, kccaFamily("kmedians"))
k51

#Let us now apply the predict function

clusters_index <- predict(k51)

dist(k51@centers)
image(k51)
points(Mydata2, col=clusters_index, pch=19, cex=0.3)
```

***
Using Manhattan distance Method each of the 5 clusters have 7, 3, 6 ,3 and 2 data points respectively.

The difference in Kmeans and kcca is that the former method uses Eucledian diatnce for measuring the distance and means of the centroids in categoriging the data points , where as , the later uses Manhattan distnace for measuring the distance betwwen centroids and Median of the centroids for categorization.

Hence, the count of data points in each cluster varies.


b.

Interpret the clusters with respect to the numerical variables used in forming the clusters

Calculating Mean for all variables for each cluster and plotting the clusters (using the Kmeans method)

```{r}
Mydata1 %>% mutate(Cluster = k5$cluster) %>% group_by(Cluster) %>% summarise_all("mean")

clusplot(Mydata2,k5$cluster, main="Clusters",color = TRUE, labels = 2,lines = 0)
```

***
Comapnies are categorized into different clusters as follows:

Cluster 1: ELN, MRX, WPI and AVE

Cluster 2: AGN and PHA

Cluster 3: AHM,WYE,BMY,AZN, LLY, ABT, NVS and SGP

Cluster 4: BAY, CHTT and IVX

Cluster 5: JNJ, MRK, PFE and GSK


From the means of the cluster variables , we can say that,

Cluster 1 has got highest revenue growth , very good Net profit Margin and leverage with lowest PE ratio. It can be bought or hold.

Cluster 2 PE ratio is very high , inferring that investors are expecting high growth , however, growth rate is only 12% and Net profit Margin is also low , making it overvalued and may not be a good choice overall.

Cluster 3 has average risk (Beta) and relatively high Market Cap, ROE, ROA, Asset Turnover and Net Profit Margin ,high leverage.Attractive (relatively low) PE ratio indicates that the stock price is moderately valued hence can be bought and hold , making it ideal to own.

Cluster 4 Though it has a good PE ratio, it carries a very high risk , very very high leverage and low Net Profit margin , making it very risky to own. Revenue growth is also very low.

Cluster 5 is great with High Market Cap, ROE, ROA, Asset Turnover and Net Profit Margin. With a relatively low PE ratio the stock price is moderately valued, hence can be bought and hold.Further , revenue growth of 18.5% is good.


c.

Is there a pattern in the clusters with respect to the numerical variables (10 to 12)? (those not used in
forming the clusters)

We will add the respective cluster numbers for each data point and add thae cloumn called Clusters to the data frame (Mydata3) , containing the original three non-numeric variables.

We will plot the clusters as against the variables to check for any patterns.

```{r}
Mydata3 <- Mydata[12:14] %>% mutate(Clusters=k5$cluster)

ggplot(Mydata3, mapping = aes(factor(Clusters), fill =Median_Recommendation))+geom_bar(position='dodge')+labs(x ='Clusters')

ggplot(Mydata3, mapping = aes(factor(Clusters),fill = Location))+geom_bar(position = 'dodge')+labs(x ='Clusters')
ggplot(Mydata3, mapping = aes(factor(Clusters),fill = Exchange))+geom_bar(position = 'dodge')+labs(x ='Clusters')
```

***
1.Apparently, there is a pattern between clusters and the variable Median_Recommendation.

By and large , cluster description given in point 'b' above is in line with Median_Recommendation for all clusters except 2 and 4.

2.It appears that there is no evident pattern among the clusters, Location and Exchange, except for the fact that majority of the clusters/companies are listed on NYSE and located in the USA.


d.

Provide an appropriate name for each cluster using any or all of the variables in the dataset.

Cluster 1: BestBuy (Buy,Hold) 

Cluster 2: High Risk (Sell)

Cluster 3: Go for it (Buy,Hold)

Cluster 4: Very Risky or Runaway (Sell)

Cluster 5: Ideal to Own (Buy,Hold) 

